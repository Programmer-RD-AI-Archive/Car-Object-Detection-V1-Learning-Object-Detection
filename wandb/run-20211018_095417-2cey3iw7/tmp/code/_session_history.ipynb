{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5eb2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json,cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch,torchvision\n",
    "import wandb\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcd371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "device = 'cuda'\n",
    "PROJECT_NAME = 'Car-Object-Detection-V1-Learning-Object-Detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "404c1cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1.9.1+cu111', '0.10.1+cu111', '0.12.1', '2.0.9', '1.3.3', '1.20.3')"
     ]
    }
   ],
   "source": [
    "torch.__version__,torchvision.__version__,wandb.__version__,json.__version__,pd.__version__,np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ea7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv').sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39bbd999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               image        xmin        ymin        xmax        ymax\n",
      "142  vid_4_17140.jpg  544.908828  174.808559  657.412446  229.094273\n",
      "289  vid_4_22980.jpg  536.104197  182.144466  656.434153  225.181789\n",
      "518   vid_4_9420.jpg  424.900218  174.694786  532.725419  219.487532\n",
      "12   vid_4_10520.jpg    0.000000  195.349099   36.685962  234.473938\n",
      "359  vid_4_28860.jpg   80.219971  193.392857  168.266281  231.539575\n",
      "..               ...         ...         ...         ...         ...\n",
      "255   vid_4_2140.jpg  464.199711  180.188224  659.858177  251.591055\n",
      "417   vid_4_6180.jpg  425.068017  177.253861  559.094067  225.181789\n",
      "110  vid_4_14400.jpg    0.000000  190.947555   55.273517  228.116152\n",
      "231   vid_4_2060.jpg  491.591896  184.589768  597.736614  222.736487\n",
      "349  vid_4_26580.jpg    0.000000  195.838160   50.382055  223.714607\n",
      "\n",
      "[559 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f01ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/vid_4_12300.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c377b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin,ymin,xmax,ymax = 386,185,554,230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf54db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ca803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = img[y:y+h,x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "386459cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<matplotlib.image.AxesImage at 0x7f3c65793bd0>"
     ]
    }
   ],
   "source": [
    "plt.imshow(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ccde2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "cv2.imwrite('./crop.png',crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f41e336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<matplotlib.image.AxesImage at 0x7f3c65726ed0>"
     ]
    }
   ],
   "source": [
    "plt.imshow(cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a06f2f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "cv2.imwrite('./box.png',cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc4eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    new_data = []\n",
    "    for idx in range(len(data)):\n",
    "        new_data_iter = []\n",
    "        info = data.iloc[idx]\n",
    "        new_data.append([\n",
    "            cv2.resize(cv2.imread(f'./data/{info[\"image\"]}'),(112,112))/255.0,\n",
    "            [info['xmin'],info['ymin'],info['xmax'],info['ymax']]\n",
    "        ])\n",
    "    X = []\n",
    "    y = []\n",
    "    for d in new_data:\n",
    "        X.append(d[0])\n",
    "        y.append(d[1])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,shuffle=False)\n",
    "    X_train = torch.from_numpy(np.array(X_train)).to(device).view(-1,3,56,56).float()\n",
    "    y_train = torch.from_numpy(np.array(y_train)).to(device).float()\n",
    "    X_test = torch.from_numpy(np.array(X_test)).to(device).view(-1,3,56,56).float()\n",
    "    y_test = torch.from_numpy(np.array(y_test)).to(device).float()\n",
    "    return X,y,X_train,X_test,y_train,y_test,new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d23076f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,X_train,X_test,y_train,y_test,new_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "658d9624",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_train,'X_train.pt')\n",
    "torch.save(y_train,'y_train.pt')\n",
    "torch.save(X_test,'X_test.pt')\n",
    "torch.save(y_test,'y_test.pt')\n",
    "torch.save(X_train,'X_train.pth')\n",
    "torch.save(y_train,'y_train.pth')\n",
    "torch.save(X_test,'X_test.pth')\n",
    "torch.save(y_test,'y_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b55887b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f55935d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y):\n",
    "    preds = model(X)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred,yb in zip(preds,y):\n",
    "        pred = int(torch.argmax(pred))\n",
    "        yb = int(torch.argmax(yb))\n",
    "        if pred == yb:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c872301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True).to(device)\n",
    "model.fc = Linear(512,4)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e5cd86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline-TL-True</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V1-Learning-Object-Detection\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Object-Detection-V1-Learning-Object-Detection</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V1-Learning-Object-Detection/runs/2cey3iw7\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Object-Detection-V1-Learning-Object-Detection/runs/2cey3iw7</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/Object-Detection/Car-Object-Detection-V1-Learning-Object-Detection/wandb/run-20211018_095417-2cey3iw7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline-TL-True')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val ACC':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f09af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32"
     ]
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db0817d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, torch.Size([32, 4]))"
     ]
    }
   ],
   "source": [
    "batch_size,preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "427770c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([23, 4]), torch.Size([32, 4]))"
     ]
    }
   ],
   "source": [
    "y_batch.shape,preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54d17903",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline-TL-True')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        try:\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "            model.to(device)\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds,y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except:\n",
    "            pass\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val ACC':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
