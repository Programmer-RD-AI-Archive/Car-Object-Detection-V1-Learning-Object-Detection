{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc0efcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json,cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch,torchvision\n",
    "import wandb\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7faa4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "device = 'cuda'\n",
    "PROJECT_NAME = 'Car-Object-Detection-V1-Learning-Object-Detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618d6595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1.9.1+cu111', '0.10.1+cu111', '0.12.1', '2.0.9', '1.3.3', '1.20.3')"
     ]
    }
   ],
   "source": [
    "torch.__version__,torchvision.__version__,wandb.__version__,json.__version__,pd.__version__,np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2582f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv').sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcf8240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               image        xmin        ymin        xmax        ymax\n",
      "142  vid_4_17140.jpg  544.908828  174.808559  657.412446  229.094273\n",
      "289  vid_4_22980.jpg  536.104197  182.144466  656.434153  225.181789\n",
      "518   vid_4_9420.jpg  424.900218  174.694786  532.725419  219.487532\n",
      "12   vid_4_10520.jpg    0.000000  195.349099   36.685962  234.473938\n",
      "359  vid_4_28860.jpg   80.219971  193.392857  168.266281  231.539575\n",
      "..               ...         ...         ...         ...         ...\n",
      "255   vid_4_2140.jpg  464.199711  180.188224  659.858177  251.591055\n",
      "417   vid_4_6180.jpg  425.068017  177.253861  559.094067  225.181789\n",
      "110  vid_4_14400.jpg    0.000000  190.947555   55.273517  228.116152\n",
      "231   vid_4_2060.jpg  491.591896  184.589768  597.736614  222.736487\n",
      "349  vid_4_26580.jpg    0.000000  195.838160   50.382055  223.714607\n",
      "\n",
      "[559 rows x 5 columns]"
     ]
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546dca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./data/vid_4_12300.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f59b126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin,ymin,xmax,ymax = 386,185,554,230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9c0b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xmin\n",
    "y = ymin\n",
    "w = xmax - xmin\n",
    "h = ymax - ymin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f113c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = img[y:y+h,x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e79c0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<matplotlib.image.AxesImage at 0x7f3c65793bd0>"
     ]
    }
   ],
   "source": [
    "plt.imshow(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c0323c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "cv2.imwrite('./crop.png',crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73556a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<matplotlib.image.AxesImage at 0x7f3c65726ed0>"
     ]
    }
   ],
   "source": [
    "plt.imshow(cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d87576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    }
   ],
   "source": [
    "cv2.imwrite('./box.png',cv2.rectangle(img,(x,y),(x+w,y+h),(200,0,0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f30ec591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    new_data = []\n",
    "    for idx in range(len(data)):\n",
    "        new_data_iter = []\n",
    "        info = data.iloc[idx]\n",
    "        new_data.append([\n",
    "            cv2.resize(cv2.imread(f'./data/{info[\"image\"]}'),(112,112))/255.0,\n",
    "            [info['xmin'],info['ymin'],info['xmax'],info['ymax']]\n",
    "        ])\n",
    "    X = []\n",
    "    y = []\n",
    "    for d in new_data:\n",
    "        X.append(d[0])\n",
    "        y.append(d[1])\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,shuffle=False)\n",
    "    X_train = torch.from_numpy(np.array(X_train)).to(device).view(-1,3,56,56).float()\n",
    "    y_train = torch.from_numpy(np.array(y_train)).to(device).float()\n",
    "    X_test = torch.from_numpy(np.array(X_test)).to(device).view(-1,3,56,56).float()\n",
    "    y_test = torch.from_numpy(np.array(y_test)).to(device).float()\n",
    "    return X,y,X_train,X_test,y_train,y_test,new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0461e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,X_train,X_test,y_train,y_test,new_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "974e23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_train,'X_train.pt')\n",
    "torch.save(y_train,'y_train.pt')\n",
    "torch.save(X_test,'X_test.pt')\n",
    "torch.save(y_test,'y_test.pt')\n",
    "torch.save(X_train,'X_train.pth')\n",
    "torch.save(y_train,'y_train.pth')\n",
    "torch.save(X_test,'X_test.pth')\n",
    "torch.save(y_test,'y_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e9687c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(model,X,y,criterion):\n",
    "    preds = model(X)\n",
    "    loss = criterion(preds,y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5866e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model,X,y):\n",
    "    preds = model(X)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for pred,yb in zip(preds,y):\n",
    "        pred = int(torch.argmax(pred))\n",
    "        yb = int(torch.argmax(yb))\n",
    "        if pred == yb:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "500cceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True).to(device)\n",
    "model.fc = Linear(512,4)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69a6347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline-TL-True')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "        model.to(device)\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val ACC':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56a8d8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32"
     ]
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4aebb6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, torch.Size([32, 4]))"
     ]
    }
   ],
   "source": [
    "batch_size,preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49304b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([23, 4]), torch.Size([32, 4]))"
     ]
    }
   ],
   "source": [
    "y_batch.shape,preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e7a734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline-TL-True')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        try:\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "            model.to(device)\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds,y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except:\n",
    "            pass\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val ACC':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62f9d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "691c5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.max_pool2d = MaxPool2d((2,2),(2,2))\n",
    "        self.activation = ReLU()\n",
    "        self.conv1 = Conv2d(3,7,(5,5))\n",
    "        self.conv2 = Conv2d(7,14,(5,5))\n",
    "        self.conv2bn = BatchNorm2d(14)\n",
    "        self.conv3 = Conv2d(14,21,(5,5))\n",
    "        self.linear1 = Linear(21*3*3,256)\n",
    "        self.linear2 = Linear(256,512)\n",
    "        self.linear2bn = BatchNorm1d(512)\n",
    "        self.linear3 = Linear(512,256)\n",
    "        self.output = Linear(256,len(labels))\n",
    "        \n",
    "    def forward(self,X):\n",
    "        preds = self.max_pool2d(self.activation(self.conv1(X)))\n",
    "        preds = self.max_pool2d(self.activation(self.conv2bn(self.conv2(preds))))\n",
    "        preds = self.max_pool2d(self.activation(self.conv3(preds)))\n",
    "        preds = preds.view(-1,21*3*3)\n",
    "        preds = self.activation(self.linear1(preds))\n",
    "        preds = self.activation(self.linear2bn(self.linear2(preds)))\n",
    "        preds = self.activation(self.linear3(preds))\n",
    "        preds = self.output(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43ef18e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b58e1507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2taznulh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 149432<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccbca7d2ff344ae91a811843f29beae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.04MB of 0.04MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/Object-Detection/Car-Object-Detection-V1-Learning-Object-Detection/wandb/run-20211018_095542-2taznulh/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/Object-Detection/Car-Object-Detection-V1-Learning-Object-Detection/wandb/run-20211018_095542-2taznulh/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">baseline-TL-True</strong>: <a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V1-Learning-Object-Detection/runs/2taznulh\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Object-Detection-V1-Learning-Object-Detection/runs/2taznulh</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2taznulh). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline-CNN</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V1-Learning-Object-Detection\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Object-Detection-V1-Learning-Object-Detection</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Car-Object-Detection-V1-Learning-Object-Detection/runs/ev2yqx9t\" target=\"_blank\">https://wandb.ai/ranuga-d/Car-Object-Detection-V1-Learning-Object-Detection/runs/ev2yqx9t</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/Object-Detection/Car-Object-Detection-V1-Learning-Object-Detection/wandb/run-20211018_095609-ev2yqx9t</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline-CNN')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        try:\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "            model.to(device)\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds,y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except:\n",
    "            pass\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val ACC':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b7af06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.max_pool2d = MaxPool2d((2,2),(2,2))\n",
    "        self.activation = ReLU()\n",
    "        self.conv1 = Conv2d(3,7,(5,5))\n",
    "        self.conv2 = Conv2d(7,14,(5,5))\n",
    "        self.conv2bn = BatchNorm2d(14)\n",
    "        self.conv3 = Conv2d(14,21,(5,5))\n",
    "        self.linear1 = Linear(21*3*3,256)\n",
    "        self.linear2 = Linear(256,512)\n",
    "        self.linear2bn = BatchNorm1d(512)\n",
    "        self.linear3 = Linear(512,256)\n",
    "        self.output = Linear(256,4)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        preds = self.max_pool2d(self.activation(self.conv1(X)))\n",
    "        preds = self.max_pool2d(self.activation(self.conv2bn(self.conv2(preds))))\n",
    "        preds = self.max_pool2d(self.activation(self.conv3(preds)))\n",
    "        preds = preds.view(-1,21*3*3)\n",
    "        preds = self.activation(self.linear1(preds))\n",
    "        preds = self.activation(self.linear2bn(self.linear2(preds)))\n",
    "        preds = self.activation(self.linear3(preds))\n",
    "        preds = self.output(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22b2bdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "criterion = MSELoss()\n",
    "optimizer = Adam(model.parameters(),lr=0.001)\n",
    "epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "871e0a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline-CNN')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for i in range(0,len(X_train),batch_size):\n",
    "        try:\n",
    "            X_batch = X_train[i:i+batch_size]\n",
    "            y_batch = y_train[i:i+batch_size]\n",
    "            model.to(device)\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds,y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        except:\n",
    "            pass\n",
    "    model.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Loss':(get_loss(model,X_train,y_train,criterion)+get_loss(model,X_batch,y_batch,criterion))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val Loss':get_loss(model,X_test,y_test,criterion)})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Acc':(get_accuracy(model,X_train,y_train)+get_accuracy(model,X_batch,y_batch))/2})\n",
    "    torch.cuda.empty_cache()\n",
    "    wandb.log({'Val ACC':get_accuracy(model,X_test,y_test)})\n",
    "    torch.cuda.empty_cache()\n",
    "    model.train()\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
